inherit: 
    - wandb.yaml

model:
    family: gpt2
    n_embd: 128
    n_layer: 2
    n_head: 8
    n_positions: 1024
    n_dims: 20
    interleave: True

training:
    task: filter_linear_regression
    task_kwargs: {}
    data: filter
    data_sampler_kwargs: {"prob": 0.9}
    batch_size: 64
    learning_rate: 0.0001
    gradient_clip: 10.0
    save_every_steps: 1000
    keep_every_steps: 100000
    train_steps: 1000001
    curriculum:
        dims:
            start: 4
            end: 20
            inc: 1
            interval: 2000
        points:
            start: 12
            end: 512
            inc: 2
            interval: 200

out_dir: ../models/filter_LR_long

wandb:
    name: "512_pr0.9_tf_embd128_layer2_lr1e-4"