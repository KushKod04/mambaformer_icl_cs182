config: conf/long_term_dependency.yaml
inherit:
- /home/ubuntu/cs182/mambaformer-icl/src/conf/wandb.yaml
model:
  family: gpt2
  interleave: true
  mixed_attn: null
  n_dims: 20
  n_embd: 512
  n_head: 8
  n_layer: 8
  n_positions: 256
  vocab_size: -1
out_dir: ../models/long_term_dependency/LTD_gpt2_embd512_layer8_lr1e-4_2025-04-22-00:55:01
test_run: false
training:
  batch_size: 64
  curriculum:
    dims:
      end: 20
      inc: 1
      interval: 2000
      start: 20
    points:
      end: 64
      inc: 2
      interval: 2000
      start: 64
  data: gaussian_for_retrieval
  data_sampler_kwargs: {}
  device_batch_size: null
  do_parallel: null
  gradient_clip: 10.0
  keep_every_steps: 100000
  learning_rate: 0.0001
  num_tasks: null
  num_training_examples: null
  resume_id: null
  save_every_steps: 5000
  task: long_term_dependency
  task_kwargs: {}
  train_steps: 100001
wandb:
  entity: kkodnad-bair-malik-lab
  log_every_steps: 1000
  name: LTD_gpt2_embd512_layer8_lr1e-4
  notes: ''
  project: cs182_project
